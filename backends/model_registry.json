[
  {
    "model_name": "openchat",
    "model_id": "openchat-3.5-0106",
    "backend": "openai_compatible",
    "release_date": "06-01-24",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "codellama-34b",
    "model_id": "codellama-34b-instruct",
    "backend": "openai_compatible",
    "release_date": "24-08-23",
    "open_weight": true,
    "parameters": "34B"
  },
  {
    "model_name": "Llama-3-70B-Instruct-Anyscale",
    "model_id": "meta-llama/Meta-Llama-3-70B-Instruct",
    "backend": "openai_compatible",
    "release_date": "18-04-24",
    "open_weight": true,
    "parameters": "70B"
  },
  {
    "model_name": "Llama-3-70B-Together.ai",
    "model_id": "meta-llama/Llama-3-70b-chat-hf",
    "backend": "openai_compatible",
    "release_date": "18-04-24",
    "open_weight": true,
    "parameters": "70B"
  },
  {
    "model_name": "Llama-3-8B-Together.ai",
    "model_id": "meta-llama/Llama-3-8b-chat-hf",
    "backend": "openai_compatible",
    "release_date": "18-04-24",
    "open_weight": true,
    "parameters": "8B"
  },
  {
    "model_name": "Llama-3-8B-Instruct-Anyscale",
    "model_id": "meta-llama/Meta-Llama-3-8B-Instruct",
    "backend": "openai_compatible",
    "release_date": "18-04-24",
    "open_weight": true,
    "parameters": "8B"
  },
  {
    "model_name": "Meta-Llama-3.1-405B-Instruct-Turbo",
    "model_id": "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo",
    "backend": "openai_compatible",
    "release_date": "23-07-24",
    "open_weight": true,
    "parameters": "405B"
  },
  {
    "model_name": "Mixtral-8x22B-Instruct-v0.1",
    "model_id": "mistralai/Mixtral-8x22B-Instruct-v0.1",
    "backend": "openai_compatible",
    "release_date": "17-04-24",
    "open_weight": true,
    "parameters": "141B"
  },
  {
    "model_name": "Mixtral-8x7B-Instruct-v0.1",
    "model_id": "mistralai/Mixtral-8x7B-Instruct-v0.1",
    "backend": "openai_compatible",
    "release_date": "11-12-23",
    "open_weight": true,
    "parameters": "46.7B"
  },
  {
    "model_name": "fsc-openchat-3.5-0106",
    "model_id": "openchat-3.5-0106",
    "backend": "openai_compatible",
    "release_date": "06-01-24",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "fsc-codellama-34b-instruct",
    "model_id": "codellama-34b-instruct",
    "backend": "openai_compatible",
    "release_date": "24-08-23",
    "open_weight": true,
    "parameters": "34B"
  },
  {
    "model_name": "gpt-4-1106-vision-preview",
    "model_id": "gpt-4-1106-vision-preview",
    "backend": "openai",
    "supports_images": true,
    "support_multiple_images": true,
    "release_date": "06-11-23",
    "open_weight": false,
    "parameters": "",
    "estimated_parameters": "1.76T"
  },
  {
    "model_name": "gpt-4o-2024-05-13",
    "model_id": "gpt-4o-2024-05-13",
    "backend": "openai",
    "supports_images": true,
    "support_multiple_images": true,
    "release_date": "13-05-24",
    "open_weight": false,
    "parameters": "",
    "estimated_parameters": "200B"
  },
  {
    "model_name": "gpt-4o-2024-08-06",
    "model_id": "gpt-4o-2024-08-06",
    "backend": "openai",
    "supports_images": true,
    "support_multiple_images": true,
    "release_date": "06-08-24",
    "open_weight": false,
    "parameters": "",
    "estimated_parameters": "200B"
  },
  {
    "model_name": "gpt-4o-mini-2024-07-18",
    "model_id": "gpt-4o-mini-2024-07-18",
    "backend": "openai",
    "supports_images": true,
    "support_multiple_images": true,
    "release_date": "18-07-24",
    "open_weight": false,
    "parameters": "",
    "estimated_parameters": "8B"
  },
  {
    "model_name": "gpt-4-turbo-2024-04-09",
    "model_id": "gpt-4-turbo-2024-04-09",
    "backend": "openai",
    "release_date": "09-04-24",
    "open_weight": false,
    "parameters": "1.76T"
  },
  {
    "model_name": "gpt-4-1106-preview",
    "model_id": "gpt-4-1106-preview",
    "backend": "openai",
    "release_date": "06-11-23",
    "open_weight": false,
    "parameters": "1.76T"
  },
  {
    "model_name": "gpt-4-0125-preview",
    "model_id": "gpt-4-0125-preview",
    "backend": "openai",
    "release_date": "25-01-24",
    "open_weight": false,
    "parameters": "1.76T"
  },
  {
    "model_name": "gpt-3.5-turbo-0125",
    "model_id": "gpt-3.5-turbo-0125",
    "backend": "openai",
    "release_date": "25-01-24",
    "open_weight": false,
    "parameters": "175B"
  },
  {
    "model_name": "gpt-4-0613",
    "model_id": "gpt-4-0613",
    "backend": "openai",
    "release_date": "13-06-23",
    "open_weight": false,
    "parameters": "1.76T"
  },
  {
    "model_name": "gpt-4-0314",
    "model_id": "gpt-4-0314",
    "backend": "openai",
    "release_date": "14-03-23",
    "open_weight": false,
    "parameters": "1.76T"
  },
  {
    "model_name": "gpt-3.5-turbo-1106",
    "model_id": "gpt-3.5-turbo-1106",
    "backend": "openai",
    "release_date": "06-11-23",
    "open_weight": false,
    "parameters": "175B"
  },
  {
    "model_name": "gpt-3.5-turbo-0613",
    "model_id": "gpt-3.5-turbo-0613",
    "backend": "openai",
    "release_date": "13-06-23",
    "open_weight": false,
    "parameters": "175B"
  },
  {
    "model_name": "mistral-medium-2312",
    "model_id": "mistral-medium-2312",
    "backend": "mistral",
    "release_date": "01-12-23",
    "open_weight": true,
    "parameters": "",
    "estimated_parameters": "141B"
  },
  {
    "model_name": "mistral-tiny-2312",
    "model_id": "mistral-tiny-2312",
    "backend": "mistral",
    "release_date": "01-12-23",
    "open_weight": true,
    "parameters": "",
    "estimated_parameters": "7B"
  },
  {
    "model_name": "mistral-small-2312",
    "model_id": "mistral-small-2312",
    "backend": "mistral",
    "release_date": "01-12-23",
    "open_weight": true,
    "parameters": "",
    "estimated_parameters": "46.7B"
  },
  {
    "model_name": "mistral-large-2402",
    "model_id": "mistral-large-2402",
    "backend": "mistral",
    "release_date": "01-02-24",
    "open_weight": true,
    "parameters": "123B"
  },
  {
    "model_name": "command",
    "model_id": "command",
    "backend": "cohere",
    "release_date": "01-12-22",
    "open_weight": false,
    "parameters": "",
    "estimated_parameters": ""
  },
  {
    "model_name": "command-r",
    "model_id": "command-r",
    "backend": "cohere",
    "release_date": "01-03-24",
    "open_weight": true,
    "parameters": "35B"
  },
  {
    "model_name": "command-r-plus",
    "model_id": "command-r-plus",
    "backend": "cohere",
    "release_date": "01-04-24",
    "open_weight": true,
    "parameters": "104B"
  },
  {
    "model_name": "command-light",
    "model_id": "command-light",
    "backend": "cohere",
    "release_date": "01-12-22",
    "open_weight": false,
    "parameters": "",
    "estimated_parameters": ""
  },
  {
    "model_name": "claude-v1.3",
    "model_id": "claude-v1.3",
    "backend": "anthropic",
    "release_date": "18-04-23",
    "open_weight": false,
    "parameters": "",
    "estimated_parameters": ""
  },
  {
    "model_name": "claude-v1.3-100k",
    "model_id": "claude-v1.3-100k",
    "backend": "anthropic",
    "release_date": "18-03-23",
    "open_weight": false,
    "parameters": "",
    "estimated_parameters": ""
  },
  {
    "model_name": "claude-instant-1.2",
    "model_id": "claude-instant-1.2",
    "backend": "anthropic",
    "release_date": "09-08-23",
    "open_weight": false,
    "parameters": "",
    "estimated_parameters": ""
  },
  {
    "model_name": "claude-2",
    "model_id": "claude-2",
    "backend": "anthropic",
    "release_date": "11-07-23",
    "open_weight": false,
    "parameters": "137B"
  },
  {
    "model_name": "claude-2.1",
    "model_id": "claude-2.1",
    "backend": "anthropic",
    "release_date": "21-11-23",
    "open_weight": false,
    "parameters": "137B"
  },
  {
    "model_name": "claude-3-opus-20240229",
    "model_id": "claude-3-opus-20240229",
    "backend": "anthropic",
    "supports_images": true,
    "support_multiple_images": true,
    "release_date": "29-02-24",
    "open_weight": false,
    "parameters": "2T"
  },
  {
    "model_name": "claude-3-sonnet-20240229",
    "model_id": "claude-3-sonnet-20240229",
    "backend": "anthropic",
    "supports_images": true,
    "support_multiple_images": true,
    "release_date": "29-02-24",
    "open_weight": false,
    "parameters": "70B"
  },
  {
    "model_name": "claude-3-haiku-20240307",
    "model_id": "claude-3-haiku-20240307",
    "backend": "anthropic",
    "supports_images": true,
    "support_multiple_images": true,
    "release_date": "07-03-24",
    "open_weight": false,
    "parameters": "20B"
  },
  {
    "model_name": "claude-3-5-sonnet-20240620",
    "model_id": "claude-3-5-sonnet-20240620",
    "backend": "anthropic",
    "supports_images": true,
    "support_multiple_images": true,
    "release_date": "20-06-24",
    "open_weight": false,
    "parameters": "",
    "estimated_parameters": ""
  },
  {
    "model_name": "gemini-1.0-pro-001",
    "model_id": "gemini-1.0-pro-001",
    "backend": "google",
    "release_date": "15-02-24",
    "open_weight": false,
    "parameters": "",
    "estimated_parameters": ""
  },
 {
    "model_name": "gemini-1.0-pro-002",
    "model_id": "gemini-1.0-pro-002",
    "backend": "google",
    "release_date": "09-04-24",
    "open_weight": false,
    "parameters": "",
    "estimated_parameters": ""
  },
  {
    "model_name": "gemini-1.0-pro-vision-001",
    "model_id": "gemini-1.0-pro-vision-latest",
    "backend": "google",
    "supports_images": true,
    "support_multiple_images": true,
    "release_date": "15-02-24",
    "open_weight": false,
    "parameters": "",
    "estimated_parameters": ""
  },
  {
    "model_name": "gemini-1.5-flash-001",
    "model_id": "gemini-1.5-flash-001",
    "backend": "google",
    "supports_images": true,
    "support_multiple_images": true,
    "release_date": "24-05-24",
    "open_weight": false,
    "parameters": "",
    "estimated_parameters": ""
  },
  {
    "model_name": "gemini-1.5-pro-001",
    "model_id": "gemini-1.5-pro-001",
    "backend": "google",
    "supports_images": true,
    "support_multiple_images": true,
    "release_date": "24-05-24",
    "open_weight": false,
    "parameters": "1.5T"
  },
  {
    "model_name": "gemini-1.5-pro-exp-0801",
    "model_id": "gemini-1.5-pro-exp-0801",
    "backend": "google",
    "supports_images": true,
    "support_multiple_images": true,
    "release_date": "01-08-24",
    "open_weight": false,
    "parameters": "1.5T"
  },
  {
    "model_name": "luminous-supreme-control",
    "model_id": "luminous-supreme-control",
    "backend": "alephalpha",
    "release_date": "13-02-23",
    "open_weight": false,
    "parameters": "70B"
  },
  {
    "model_name": "luminous-supreme",
    "model_id": "luminous-supreme",
    "backend": "alephalpha",
    "release_date": "15-08-22",
    "open_weight": false,
    "parameters": "70B"
  },
  {
    "model_name": "luminous-extended",
    "model_id": "luminous-extended",
    "backend": "alephalpha",
    "release_date": "15-06-22",
    "open_weight": false,
    "parameters": "30B"
  },
  {
    "model_name": "luminous-base",
    "model_id": "luminous-base",
    "backend": "alephalpha",
    "release_date": "14-04-22",
    "open_weight": false,
    "parameters": "13B"
  },
  {
    "model_name": "Mistral-7B-Instruct-v0.1",
    "backend": "huggingface_local",
    "huggingface_id": "mistralai/Mistral-7B-Instruct-v0.1",
    "premade_chat_template": true,
    "eos_to_cull": "</s>",
    "release_date": "27-09-23",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "sheep-duck-llama-2-70b-v1.1",
    "backend": "huggingface_local",
    "huggingface_id": "Riiid/sheep-duck-llama-2-70b-v1.1",
    "premade_chat_template": false,
    "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '### User:\\n' + message['content'] + '\\n\\n' }}{% elif message['role'] == 'system' %}{{ '### System:\\n' + message['content'] + '\\n\\n' }}{% elif message['role'] == 'assistant' %}{{ '### Assistant:\\n' + message['content'] + '\\n\\n' }}{% endif %}{% if loop.last %}{{ '### Assistant:\\n' }}{% endif %}{% endfor %}",
    "eos_to_cull": "</s>",
    "release_date": "27-09-23",
    "open_weight": true,
    "parameters": "70B"
  },
  {
    "model_name": "sheep-duck-llama-2-13b",
    "backend": "huggingface_local",
    "huggingface_id": "Riiid/sheep-duck-llama-2-13b",
    "premade_chat_template": false,
    "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '### User:\\n' + message['content'] + '\\n\\n' }}{% elif message['role'] == 'system' %}{{ '### System:\\n' + message['content'] + '\\n\\n' }}{% elif message['role'] == 'assistant' %}{{ '### Assistant:\\n' + message['content'] + '\\n\\n' }}{% endif %}{% if loop.last %}{{ '### Assistant:\\n' }}{% endif %}{% endfor %}",
    "eos_to_cull": "</s>",
    "release_date": "04-10-23",
    "open_weight": true,
    "parameters": "13B"
  },
  {
    "model_name": "falcon-7b-instruct",
    "backend": "huggingface_local",
    "huggingface_id": "tiiuae/falcon-7b-instruct",
    "premade_chat_template": false,
    "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + '\\n' }}{% elif message['role'] == 'assistant' %}{{ 'ASSISTANT: ' + message['content'] + '\\n' }}{% endif %}{% if loop.last %}{{ 'ASSISTANT:' }}{% endif %}{% endfor %}",
    "eos_to_cull": "<\\|endoftext\\|>",
    "release_date": "25-04-23",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "falcon-40b-instruct",
    "backend": "huggingface_local",
    "huggingface_id": "tiiuae/falcon-40b-instruct",
    "premade_chat_template": false,
    "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + '\\n' }}{% elif message['role'] == 'assistant' %}{{ 'ASSISTANT: ' + message['content'] + '\\n' }}{% endif %}{% if loop.last %}{{ 'ASSISTANT:' }}{% endif %}{% endfor %}",
    "eos_to_cull": "<\\|endoftext\\|>",
    "release_date": "25-05-23",
    "open_weight": true,
    "parameters": "40B"
  },
  {
    "model_name": "oasst-sft-4-pythia-12b-epoch-3.5",
    "backend": "huggingface_local",
    "huggingface_id": "OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5",
    "premade_chat_template": false,
    "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '<|prompter|>' + message['content'] + '<|endoftext|>' }}{% elif message['role'] == 'assistant' %}{{ '<|assistant|>' + message['content'] + '<|endoftext|>' }}{% endif %}{% if loop.last %}{{ '<|assistant|>' }}{% endif %}{% endfor %}",
    "eos_to_cull": "<\\|endoftext\\|>",
    "release_date": "03-04-23",
    "open_weight": true,
    "parameters": "12B"
  },
  {
    "model_name": "koala-13B-HF",
    "backend": "huggingface_local",
    "huggingface_id": "TheBloke/koala-13B-HF",
    "premade_chat_template": false,
    "custom_chat_template": "{{ 'BEGINNING OF CONVERSATION: ' }}{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + ' ' }}{% elif message['role'] == 'assistant' %}{{ 'GPT: ' + message['content'] + ' ' }}{% endif %}{% if loop.last %}{{ 'GPT:' }}{% endif %}{% endfor %}",
    "eos_to_cull": "</s>",
    "release_date": "07-04-23",
    "open_weight": true,
    "parameters": "13B"
  },
  {
    "model_name": "Wizard-Vicuna-13B-Uncensored-HF",
    "backend": "huggingface_local",
    "huggingface_id": "TheBloke/Wizard-Vicuna-13B-Uncensored-HF",
    "premade_chat_template": false,
    "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + '\\n' }}{% elif message['role'] == 'assistant' %}{{ 'ASSISTANT: ' + message['content'] + '</s>\\n' }}{% endif %}{% if loop.last %}{{ 'ASSISTANT:' }}{% endif %}{% endfor %}",
    "eos_to_cull": "</s>",
    "release_date": "13-05-23",
    "open_weight": true,
    "parameters": "13B"
  },
  {
    "model_name": "WizardLM-70b-v1.0",
    "backend": "huggingface_local",
    "huggingface_id": "WizardLM/WizardLM-70b-v1.0",
    "premade_chat_template": false,
    "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + '\\n' }}{% elif message['role'] == 'assistant' %}{{ 'ASSISTANT: ' + message['content'] + '</s>\\n' }}{% endif %}{% if loop.last %}{{ 'ASSISTANT:' }}{% endif %}{% endfor %}",
    "eos_to_cull": "</s>",
    "release_date": "09-08-23",
    "open_weight": true,
    "parameters": "70B"
  },
  {
    "model_name": "WizardLM-13b-v1.2",
    "backend": "huggingface_local",
    "huggingface_id": "WizardLM/WizardLM-13b-v1.2",
    "premade_chat_template": false,
    "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + '\\n' }}{% elif message['role'] == 'assistant' %}{{ 'ASSISTANT: ' + message['content'] + '</s>\\n' }}{% endif %}{% if loop.last %}{{ 'ASSISTANT:' }}{% endif %}{% endfor %}",
    "eos_to_cull": "</s>",
    "release_date": "25-07-23",
    "open_weight": true,
    "parameters": "13B"
  },
  {
    "model_name": "vicuna-7b-v1.5",
    "backend": "huggingface_local",
    "huggingface_id": "lmsys/vicuna-7b-v1.5",
    "premade_chat_template": false,
    "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + '\\n' }}{% elif message['role'] == 'assistant' %}{{ 'ASSISTANT: ' + message['content'] + '</s>\\n' }}{% endif %}{% if loop.last %}{{ 'ASSISTANT:' }}{% endif %}{% endfor %}",
    "eos_to_cull": "</s>",
    "release_date": "29-07-23",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "vicuna-13b-v1.5",
    "backend": "huggingface_local",
    "huggingface_id": "lmsys/vicuna-13b-v1.5",
    "premade_chat_template": false,
    "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + '\\n' }}{% elif message['role'] == 'assistant' %}{{ 'ASSISTANT: ' + message['content'] + '</s>\\n' }}{% endif %}{% if loop.last %}{{ 'ASSISTANT:' }}{% endif %}{% endfor %}",
    "eos_to_cull": "</s>",
    "release_date": "29-07-23",
    "open_weight": true,
    "parameters": "13B"
  },
  {
    "model_name": "vicuna-33b-v1.3",
    "backend": "huggingface_local",
    "huggingface_id": "lmsys/vicuna-33b-v1.3",
    "premade_chat_template": false,
    "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + '\\n' }}{% elif message['role'] == 'assistant' %}{{ 'ASSISTANT: ' + message['content'] + '</s>\\n' }}{% endif %}{% if loop.last %}{{ 'ASSISTANT:' }}{% endif %}{% endfor %}",
    "eos_to_cull": "</s>",
    "release_date": "21-06-23",
    "open_weight": true,
    "parameters": "33B"
  },
  {
    "model_name": "gpt4all-13b-snoozy",
    "backend": "huggingface_local",
    "huggingface_id": "nomic-ai/gpt4all-13b-snoozy",
    "premade_chat_template": false,
    "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + '\\n' }}{% elif message['role'] == 'assistant' %}{{ 'ASSISTANT: ' + message['content'] + '</s>\\n' }}{% endif %}{% if loop.last %}{{ 'ASSISTANT:' }}{% endif %}{% endfor %}",
    "eos_to_cull": "</s>",
    "release_date": "24-04-23",
    "open_weight": true,
    "parameters": "13B"
  },
  {
    "model_name": "CodeLlama-34b-Instruct-hf",
    "backend": "huggingface_local",
    "huggingface_id": "codellama/CodeLlama-34b-Instruct-hf",
    "premade_chat_template": true,
    "eos_to_cull": "</s>",
    "release_date": "24-08-23",
    "open_weight": true,
    "parameters": "34B"
  },
  {
    "model_name": "zephyr-7b-alpha",
    "backend": "huggingface_local",
    "huggingface_id": "HuggingFaceH4/zephyr-7b-alpha",
    "premade_chat_template": true,
    "eos_to_cull": "</s>",
    "release_date": "09-10-23",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "zephyr-7b-beta",
    "backend": "huggingface_local",
    "huggingface_id": "HuggingFaceH4/zephyr-7b-beta",
    "premade_chat_template": true,
    "eos_to_cull": "</s>",
    "release_date": "26-10-23",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "openchat_3.5",
    "backend": "huggingface_local",
    "huggingface_id": "openchat/openchat_3.5",
    "premade_chat_template": true,
    "eos_to_cull": "<\\|end_of_turn\\|>",
    "release_date": "30-10-23",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "Yi-34B-Chat",
    "backend": "huggingface_local",
    "huggingface_id": "01-ai/Yi-34B-Chat",
    "premade_chat_template": true,
    "slow_tokenizer": true,
    "output_split_prefix": "assistant\n",
    "eos_to_cull": "<\\|im_end\\|>",
    "release_date": "22-11-23",
    "open_weight": true,
    "parameters": "34B"
  },
  {
    "model_name": "deepseek-llm-7b-chat",
    "backend": "huggingface_local",
    "huggingface_id": "deepseek-ai/deepseek-llm-7b-chat",
    "premade_chat_template": true,
    "eos_to_cull": "<｜end▁of▁sentence｜>",
    "release_date": "29-11-23",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "deepseek-llm-67b-chat",
    "backend": "huggingface_local",
    "huggingface_id": "deepseek-ai/deepseek-llm-67b-chat",
    "premade_chat_template": true,
    "eos_to_cull": "<｜end▁of▁sentence｜>",
    "release_date": "29-11-23",
    "open_weight": true,
    "parameters": "67B"
  },
  {
    "model_name": "tulu-2-dpo-7b",
    "backend": "huggingface_local",
    "huggingface_id": "allenai/tulu-2-dpo-7b",
    "premade_chat_template": false,
    "custom_chat_template": "{% for message in messages %}\n{% if message['role'] == 'user' %}\n{{ '<|user|>\n' + message['content'] }}\n{% elif message['role'] == 'assistant' %}\n{{ '<|assistant|>\n'  + message['content'] + eos_token }}\n{% endif %}\n{% if loop.last %}\n{{ '<|assistant|>' }}\n{% endif %}\n{% endfor %}",
    "eos_to_cull": "</s>",
    "release_date": "13-11-23",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "tulu-2-dpo-70b",
    "backend": "huggingface_local",
    "huggingface_id": "allenai/tulu-2-dpo-70b",
    "premade_chat_template": false,
    "custom_chat_template": "{% for message in messages %}\n{% if message['role'] == 'user' %}\n{{ '<|user|>\n' + message['content'] }}\n{% elif message['role'] == 'assistant' %}\n{{ '<|assistant|>\n'  + message['content'] + eos_token }}\n{% endif %}\n{% if loop.last %}\n{{ '<|assistant|>' }}\n{% endif %}\n{% endfor %}",
    "eos_to_cull": "</s>",
    "release_date": "12-11-23",
    "open_weight": true,
    "parameters": "70B"
  },
  {
    "model_name": "Mixtral-8x7B-Instruct-v0.1",
    "backend": "huggingface_local",
    "huggingface_id": "mistralai/Mixtral-8x7B-Instruct-v0.1",
    "premade_chat_template": true,
    "eos_to_cull": "</s>",
    "release_date": "11-12-23",
    "open_weight": true,
    "parameters": "46.7B"
  },
  {
    "model_name": "SUS-Chat-34B",
    "backend": "huggingface_local",
    "huggingface_id": "SUSTech/SUS-Chat-34B",
    "premade_chat_template": false,
    "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Human: ' + message['content'] + '\\n\\n' }}{% elif message['role'] == 'assistant' %}{{ '### Assistant: ' + message['content'] }}{% endif %}{% if loop.last %}{{ '### Assistant: ' }}{% endif %}{% endfor %}",
    "slow_tokenizer": true,
    "eos_to_cull": "<\\|endoftext\\|>",
    "release_date": "29-11-23",
    "open_weight": true,
    "parameters": "34B"
  },
  {
    "model_name": "CodeLlama-70b-Instruct-hf",
    "backend": "huggingface_local",
    "huggingface_id": "codellama/CodeLlama-70b-Instruct-hf",
    "premade_chat_template": true,
    "eos_to_cull": "<step>",
    "release_date": "29-01-24",
    "open_weight": true,
    "parameters": "70B"
  },
  {
    "model_name": "openchat-3.5-0106",
    "backend": "huggingface_local",
    "huggingface_id": "openchat/openchat-3.5-0106",
    "premade_chat_template": true,
    "eos_to_cull": "<\\|end_of_turn\\|>",
    "release_date": "06-01-24",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "openchat-3.5-1210",
    "backend": "huggingface_local",
    "huggingface_id": "openchat/openchat-3.5-1210",
    "premade_chat_template": true,
    "eos_to_cull": "<\\|end_of_turn\\|>",
    "release_date": "10-12-23",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "Nous-Hermes-2-Mixtral-8x7B-DPO",
    "backend": "huggingface_local",
    "huggingface_id": "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO",
    "premade_chat_template": true,
    "eos_to_cull": "<\\|im_end\\|>",
    "release_date": "11-01-24",
    "open_weight": true,
    "parameters": "46.7B"
  },
  {
    "model_name": "Smaug-72B-v0.1",
    "backend": "huggingface_local",
    "huggingface_id": "abacusai/Smaug-72B-v0.1",
    "premade_chat_template": false,
    "custom_chat_template": "{% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'] %}{% else %}{% set loop_messages = messages %}{% set system_message = false %}{% endif %}{% for message in loop_messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if loop.index0 == 0 and system_message != false %}{% set content = '<<SYS>>\n' + system_message + '\n<</SYS>>\n\n' + message['content'] %}{% else %}{% set content = message['content'] %}{% endif %}{% if message['role'] == 'user' %}{{ bos_token + '[INST] ' + content.strip() + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ ' '  + content.strip() + ' ' + eos_token }}{% endif %}{% endfor %}",
    "eos_to_cull": "<\\|endoftext\\|>",
    "release_date": "02-02-24",
    "open_weight": true,
    "parameters": "72B"
  },
  {
    "model_name": "Smaug-34B-v0.1",
    "backend": "huggingface_local",
    "huggingface_id": "abacusai/Smaug-34B-v0.1",
    "premade_chat_template": false,
    "custom_chat_template": "{% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'] %}{% else %}{% set loop_messages = messages %}{% set system_message = false %}{% endif %}{% for message in loop_messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if loop.index0 == 0 and system_message != false %}{% set content = '<<SYS>>\n' + system_message + '\n<</SYS>>\n\n' + message['content'] %}{% else %}{% set content = message['content'] %}{% endif %}{% if message['role'] == 'user' %}{{ bos_token + '[INST] ' + content.strip() + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ ' '  + content.strip() + ' ' + eos_token }}{% endif %}{% endfor %}",
    "eos_to_cull": "<\\|endoftext\\|>",
    "release_date": "25-01-24",
    "open_weight": true,
    "parameters": "34B"
  },
  {
    "model_name": "Qwen1.5-7B-Chat",
    "backend": "huggingface_local",
    "huggingface_id": "Qwen/Qwen1.5-7B-Chat",
    "premade_chat_template": true,
    "eos_to_cull": "<\\|im_end\\|>",
    "release_date": "30-01-24",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "Qwen1.5-72B-Chat",
    "backend": "huggingface_local",
    "huggingface_id": "Qwen/Qwen1.5-72B-Chat",
    "premade_chat_template": true,
    "eos_to_cull": "<\\|im_end\\|>",
    "release_date": "30-01-24",
    "open_weight": true,
    "parameters": "72B"
  },
  {
    "model_name": "Swallow-70b-instruct-v0.1",
    "backend": "huggingface_local",
    "huggingface_id": "tokyotech-llm/Swallow-70b-instruct-v0.1",
    "premade_chat_template": true,
    "eos_to_cull": "</s>",
    "release_date": "19-12-23",
    "open_weight": true,
    "parameters": "70B"
  },
  {
    "model_name": "Phi-3-mini-128k-instruct",
    "backend": "huggingface_local",
    "huggingface_id": "microsoft/Phi-3-mini-128k-instruct",
    "premade_chat_template": true,
    "eos_to_cull": "<\\|endoftext\\|>",
    "release_date": "22-04-24",
    "open_weight": true,
    "parameters": "3.8B"
  },
  {
    "model_name": "Starling-LM-7B-beta",
    "backend": "huggingface_local",
    "huggingface_id": "Nexusflow/Starling-LM-7B-beta",
    "premade_chat_template": true,
    "eos_to_cull": "<\\|end_of_turn\\|>",
    "release_date": "19-03-24",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "Qwen2-7B-Instruct",
    "backend": "huggingface_local",
    "huggingface_id": "Qwen/Qwen2-7B-Instruct",
    "premade_chat_template": true,
    "eos_to_cull": "<\\|im_end\\|>",
    "release_date": "04-06-24",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "Qwen2-72B-Instruct",
    "backend": "huggingface_local",
    "huggingface_id": "Qwen/Qwen2-72B-Instruct",
    "premade_chat_template": true,
    "eos_to_cull": "<\\|im_end\\|>",
    "release_date": "28-05-24",
    "open_weight": true,
    "parameters": "72B"
  },
  {
    "model_name": "Llama-3-SauerkrautLM-70b-Instruct",
    "backend": "huggingface_local",
    "huggingface_id": "VAGOsolutions/Llama-3-SauerkrautLM-70b-Instruct",
    "premade_chat_template": true,
    "eos_to_cull": "<\\|eot_id\\|>",
    "release_date": "24-04-24",
    "open_weight": true,
    "parameters": "70B"
  },
  {
    "model_name": "aya-23-8B",
    "backend": "huggingface_local",
    "requires_api_key": true,
    "huggingface_id": "CohereForAI/aya-23-8B",
    "premade_chat_template": true,
    "eos_to_cull": "<\\|END_OF_TURN_TOKEN\\|>",
    "release_date": "19-05-24",
    "open_weight": true,
    "parameters": "8B"
  },
  {
    "model_name": "aya-23-35B",
    "backend": "huggingface_local",
    "requires_api_key": true,
    "huggingface_id": "CohereForAI/aya-23-35B",
    "premade_chat_template": true,
    "eos_to_cull": "<\\|END_OF_TURN_TOKEN\\|>",
    "release_date": "19-05-24",
    "open_weight": true,
    "parameters": "35B"
  },
  {
    "model_name": "gemma-2-9b-it",
    "backend": "huggingface_local",
    "requires_api_key": true,
    "huggingface_id": "google/gemma-2-9b-it",
    "premade_chat_template": true,
    "eos_to_cull": "<end_of_turn>\n*<eos>",
    "release_date": "24-06-24",
    "open_weight": true,
    "parameters": "9B"
  },
  {
    "model_name": "gemma-2-27b-it",
    "backend": "huggingface_local",
    "requires_api_key": true,
    "huggingface_id": "google/gemma-2-27b-it",
    "premade_chat_template": true,
    "eos_to_cull": "<end_of_turn>\n*<eos>",
    "release_date": "24-06-24",
    "open_weight": true,
    "parameters": "27B"
  },
  {
    "model_name": "llama-2-7b-chat-hf",
    "backend": "huggingface_local",
    "requires_api_key": true,
    "huggingface_id": "meta-llama/llama-2-7b-chat-hf",
    "premade_chat_template": true,
    "eos_to_cull": "</s>",
    "release_date": "18-07-23",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "llama-2-13b-chat-hf",
    "backend": "huggingface_local",
    "requires_api_key": true,
    "huggingface_id": "meta-llama/llama-2-13b-chat-hf",
    "premade_chat_template": true,
    "eos_to_cull": "</s>",
    "release_date": "18-07-23",
    "open_weight": true,
    "parameters": "13B"
  },
  {
    "model_name": "llama-2-70b-chat-hf",
    "backend": "huggingface_local",
    "requires_api_key": true,
    "huggingface_id": "meta-llama/llama-2-70b-chat-hf",
    "premade_chat_template": true,
    "eos_to_cull": "</s>",
    "release_date": "18-07-23",
    "open_weight": true,
    "parameters": "70B"
  },
  {
    "model_name": "gemma-7b-it",
    "backend": "huggingface_local",
    "requires_api_key": true,
    "huggingface_id": "google/gemma-7b-it",
    "premade_chat_template": true,
    "eos_to_cull": "<eos>",
    "release_date": "21-02-24",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "gemma-1.1-2b-it",
    "backend": "huggingface_local",
    "requires_api_key": true,
    "huggingface_id": "google/gemma-1.1-2b-it",
    "premade_chat_template": true,
    "eos_to_cull": "<eos>",
    "release_date": "26-03-24",
    "open_weight": true,
    "parameters": "2B"
  },
  {
    "model_name": "gemma-1.1-7b-it",
    "backend": "huggingface_local",
    "requires_api_key": true,
    "huggingface_id": "google/gemma-1.1-7b-it",
    "premade_chat_template": true,
    "eos_to_cull": "<eos>",
    "release_date": "26-03-24",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "codegemma-7b-it",
    "backend": "huggingface_local",
    "requires_api_key": true,
    "huggingface_id": "google/codegemma-7b-it",
    "premade_chat_template": true,
    "eos_to_cull": "<eos>",
    "release_date": "09-04-24",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "recurrentgemma-2b-it",
    "backend": "huggingface_local",
    "requires_api_key": true,
    "huggingface_id": "google/recurrentgemma-2b-it",
    "premade_chat_template": true,
    "eos_to_cull": "<eos>",
    "release_date": "09-04-24",
    "open_weight": true,
    "parameters": "2B"
  },
  {
    "model_name": "gemma-2-2b-it",
    "backend": "huggingface_local",
    "requires_api_key": true,
    "huggingface_id": "google/gemma-2-2b-it",
    "premade_chat_template": true,
    "eos_to_cull": "<eos>",
    "release_date": "16-07-24",
    "open_weight": true,
    "parameters": "2B"
  },
  {
    "model_name": "Meta-Llama-3.1-8B-Instruct",
    "backend": "huggingface_local",
    "requires_api_key": true,
    "huggingface_id": "meta-llama/Meta-Llama-3.1-8B-Instruct",
    "premade_chat_template": true,
    "eos_to_cull": "<\\|eot_id\\|>",
    "release_date": "23-07-24",
    "open_weight": true,
    "parameters": "8B"
  },
  {
    "model_name": "Meta-Llama-3.1-70B-Instruct",
    "backend": "huggingface_local",
    "requires_api_key": true,
    "huggingface_id": "meta-llama/Meta-Llama-3.1-70B-Instruct",
    "premade_chat_template": true,
    "eos_to_cull": "<\\|eot_id\\|>",
    "release_date": "23-07-24",
    "open_weight": true,
    "parameters": "70B"
  },
  {
    "model_name": "Mistral-Large-Instruct-2407",
    "backend": "huggingface_local",
    "requires_api_key": true,
    "huggingface_id": "mistralai/Mistral-Large-Instruct-2407",
    "premade_chat_template": true,
    "eos_to_cull": "</s>",
    "release_date": "24-07-24",
    "open_weight": true,
    "parameters": "123B"
  },
  {
    "model_name": "Qwen1.5-0.5B-Chat-GGUF-q8",
    "backend": "llamacpp",
    "huggingface_id": "Qwen/Qwen1.5-0.5B-Chat-GGUF",
    "filename": "*q8_0.gguf",
    "premade_chat_template": true,
    "bos_string": "<s>",
    "eos_string": "<|im_end|>",
    "eos_to_cull": "<\\|im_end\\|>",
    "release_date": "03-02-24",
    "open_weight": true,
    "parameters": "0.5B"
  },
  {
    "model_name": "CapybaraHermes-2.5-Mistral-7B-GGUF-q4",
    "backend": "llamacpp",
    "huggingface_id": "TheBloke/CapybaraHermes-2.5-Mistral-7B-GGUF",
    "filename": "*Q4_0.gguf",
    "premade_chat_template": true,
    "bos_string": "<s>",
    "eos_string": "<|im_end|>",
    "eos_to_cull": "<\\|im_end\\|>",
    "release_date": "31-01-24",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "CapybaraHermes-2.5-Mistral-7B-GGUF-q5",
    "backend": "llamacpp",
    "huggingface_id": "TheBloke/CapybaraHermes-2.5-Mistral-7B-GGUF",
    "filename": "*Q5_0.gguf",
    "premade_chat_template": true,
    "bos_string": "<s>",
    "eos_string": "<|im_end|>",
    "eos_to_cull": "<\\|im_end\\|>",
    "release_date": "31-01-24",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "CapybaraHermes-2.5-Mistral-7B-GGUF-q5-k-s",
    "backend": "llamacpp",
    "huggingface_id": "TheBloke/CapybaraHermes-2.5-Mistral-7B-GGUF",
    "filename": "*Q5_K_S.gguf",
    "premade_chat_template": true,
    "bos_string": "<s>",
    "eos_string": "<|im_end|>",
    "eos_to_cull": "<\\|im_end\\|>",
    "release_date": "31-01-24",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "EstopianMaid-13B-GGUF-q2-k",
    "backend": "llamacpp",
    "huggingface_id": "TheBloke/EstopianMaid-13B-GGUF",
    "filename": "*Q2_K.gguf",
    "premade_chat_template": false,
    "custom_chat_template": "{% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'].strip() + '\\n\\n' %}{% else %}{% set loop_messages = messages %}{% set system_message = '' %}{% endif %}{% if system_message %}{{ bos_token + system_message }}{% endif %}{% for message in loop_messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if message['role'] == 'user' %}{{bos_token + '### Instruction:\\n' + message['content'].strip() + '\\n\\n' }}{% elif message['role'] == 'assistant' %}{{ '### Response:\\n' + message['content'].strip() + eos_token + '\\n\\n' }}{% endif %}{% if loop.last and message['role'] == 'user' and add_generation_prompt %}{{ '### Response:\\n' }}{% endif %}{% endfor %}",
    "bos_string": "<s>",
    "eos_string": "</s>",
    "eos_to_cull": "</s>",
    "release_date": "26-01-24",
    "open_weight": true,
    "parameters": "13B"
  },
  {
    "model_name": "EstopianMaid-13B-GGUF-q3-k-s",
    "backend": "llamacpp",
    "huggingface_id": "TheBloke/EstopianMaid-13B-GGUF",
    "filename": "*Q3_K_S.gguf",
    "premade_chat_template": false,
    "custom_chat_template": "{% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'].strip() + '\\n\\n' %}{% else %}{% set loop_messages = messages %}{% set system_message = '' %}{% endif %}{% if system_message %}{{ bos_token + system_message }}{% endif %}{% for message in loop_messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if message['role'] == 'user' %}{{bos_token + '### Instruction:\\n' + message['content'].strip() + '\\n\\n' }}{% elif message['role'] == 'assistant' %}{{ '### Response:\\n' + message['content'].strip() + eos_token + '\\n\\n' }}{% endif %}{% if loop.last and message['role'] == 'user' and add_generation_prompt %}{{ '### Response:\\n' }}{% endif %}{% endfor %}",
    "bos_string": "<s>",
    "eos_string": "</s>",
    "eos_to_cull": "</s>",
    "release_date": "26-01-24",
    "open_weight": true,
    "parameters": "13B"
  },
  {
    "model_name": "openchat_3.5-GGUF-q5",
    "backend": "llamacpp",
    "huggingface_id": "TheBloke/openchat_3.5-GGUF",
    "filename": "*Q5_0.gguf",
    "premade_chat_template": false,
    "custom_chat_template": "{{ bos_token }}{% for message in messages %}{{ 'GPT4 Correct ' + message['role'].title() + ': ' + message['content'] + '<|end_of_turn|>'}}{% endfor %}{% if add_generation_prompt %}{{ 'GPT4 Correct Assistant:' }}{% endif %}",
    "bos_string": "<s>",
    "eos_string": "<|end_of_turn|>",
    "eos_to_cull": "<\\|end_of_turn\\|>",
    "release_date": "02-11-23",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "Meta-Llama-3-70B-Instruct-GGUF-q4",
    "backend": "llamacpp",
    "huggingface_id": "MaziyarPanahi/Meta-Llama-3-70B-Instruct-GGUF",
    "filename": "*Q4_K_M.gguf",
    "premade_chat_template": true,
    "bos_string": "<|begin_of_text|>",
    "eos_string": "<|eot_id|>",
    "eos_to_cull": "<\\|eot_id\\|>",
    "release_date": "18-04-24",
    "open_weight": true,
    "parameters": "70B"
  },
  {
    "model_name": "Meta-Llama-3-70B-Instruct-GGUF-q8",
    "backend": "llamacpp",
    "huggingface_id": "MaziyarPanahi/Meta-Llama-3-70B-Instruct-GGUF",
    "filename": "*Q8_0-00001-of-00002.gguf",
    "additional_files": ["*Q8_0-00002-of-00002.gguf"],
    "premade_chat_template": true,
    "bos_string": "<|begin_of_text|>",
    "eos_string": "<|eot_id|>",
    "eos_to_cull": "<\\|eot_id\\|>",
    "release_date": "18-04-24",
    "open_weight": true,
    "parameters": "70B"
  },
  {
    "model_name": "c4ai-command-r-plus-GGUF-q4",
    "backend": "llamacpp",
    "huggingface_id": "pmysl/c4ai-command-r-plus-GGUF",
    "filename": "*Q4_K_M-00001-of-00002.gguf",
    "additional_files": ["*Q4_K_M-00002-of-00002.gguf"],
    "premade_chat_template": true,
    "bos_string": "<BOS_TOKEN>",
    "eos_string": "<|END_OF_TURN_TOKEN|>",
    "eos_to_cull": "<\\|END_OF_TURN_TOKEN\\|>",
    "release_date": "04-04-24",
    "open_weight": true,
    "parameters": "104B"
  },
  {
    "model_name": "c4ai-command-r-plus-GGUF-q8",
    "backend": "llamacpp",
    "huggingface_id": "pmysl/c4ai-command-r-plus-GGUF",
    "filename": "*Q8_0-00001-of-00003.gguf",
    "additional_files": ["*Q8_0-00002-of-00003.gguf", "*Q8_0-00003-of-00003.gguf"],
    "premade_chat_template": true,
    "bos_string": "<BOS_TOKEN>",
    "eos_string": "<|END_OF_TURN_TOKEN|>",
    "eos_to_cull": "<\\|END_OF_TURN_TOKEN\\|>",
    "release_date": "04-04-24",
    "open_weight": true,
    "parameters": "104B"
  },
  {
    "model_name": "InternVL2-Llama3-76B",
    "backend": "huggingface_multimodal",
    "huggingface_id": "OpenGVLab/InternVL2-Llama3-76B",
    "automodel_type": "transformers.AutoModel",
    "model_class": "backends.multimodal_utils.internvl_utils.InternvlMLLM",
    "use_tokenizer": true,
    "supports_multiple_images": true,
    "trust_remote_code": true,
    "use_bf16": true,
    "use_fast": false,
    "output_split_prefix": "Assistant:",
    "load_in_8bit": false,
    "low_cpu_mem_usage": true,
    "custom_device_map": true,
    "device_map": "backends.multimodal_utils.internvl_utils.split_model",
    "release_date": "15-07-24",
    "open_weight": true,
    "parameters": "76B"
  },
  {
    "model_name": "InternVL2-40B",
    "backend": "huggingface_multimodal",
    "huggingface_id": "OpenGVLab/InternVL2-40B",
    "automodel_type": "transformers.AutoModel",
    "model_class": "backends.multimodal_utils.internvl_utils.InternvlMLLM",
    "use_tokenizer": true,
    "supports_multiple_images": true,
    "trust_remote_code": true,
    "use_bf16": true,
    "use_fast": false,
    "output_split_prefix": "Assistant:",
    "load_in_8bit": false,
    "low_cpu_mem_usage": true,
    "custom_device_map": true,
    "device_map": "backends.multimodal_utils.internvl_utils.split_model",
    "release_date": "15-07-24",
    "open_weight": true,
    "parameters": "40B"
  },
  {
    "model_name": "InternVL2-26B",
    "backend": "huggingface_multimodal",
    "huggingface_id": "OpenGVLab/InternVL2-26B",
    "automodel_type": "transformers.AutoModel",
    "model_class": "backends.multimodal_utils.internvl_utils.InternvlMLLM",
    "use_tokenizer": true,
    "supports_multiple_images": true,
    "trust_remote_code": true,
    "use_bf16": true,
    "use_fast": false,
    "output_split_prefix": "Assistant:",
    "load_in_8bit": false,
    "low_cpu_mem_usage": true,
    "custom_device_map": true,
    "device_map": "backends.multimodal_utils.internvl_utils.split_model",
    "release_date": "15-07-24",
    "open_weight": true,
    "parameters": "26B"
  },
  {
    "model_name": "InternVL2-8B",
    "backend": "huggingface_multimodal",
    "huggingface_id": "OpenGVLab/InternVL2-8B",
    "automodel_type": "transformers.AutoModel",
    "model_class": "backends.multimodal_utils.internvl_utils.InternvlMLLM",
    "use_tokenizer": true,
    "supports_multiple_images": true,
    "trust_remote_code": true,
    "use_bf16": true,
    "use_fast": false,
    "output_split_prefix": "Assistant:",
    "load_in_8bit": false,
    "low_cpu_mem_usage": true,
    "custom_device_map": true,
    "device_map": "backends.multimodal_utils.internvl_utils.split_model",
    "release_date": "15-07-24",
    "open_weight": true,
    "parameters": "8B"
  },
  {
    "model_name": "internlm-xcomposer2d5-7b",
    "backend": "huggingface_multimodal",
    "huggingface_id": "internlm/internlm-xcomposer2d5-7b",
    "automodel_type": "transformers.AutoModel",
    "model_class": "backends.multimodal_utils.intern_utils.InternlmMLLM",
    "use_tokenizer": true,
    "supports_multiple_images": true,
    "trust_remote_code": true,
    "use_bf16": true,
    "output_split_prefix": "",
    "not_distributed": true,
    "release_date": "02-07-24",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "Idefics3-8B-Llama3",
    "backend": "huggingface_multimodal",
    "huggingface_id": "HuggingFaceM4/Idefics3-8B-Llama3",
    "automodel_type": "transformers.AutoModelForVision2Seq",
    "model_class": "backends.multimodal_utils.idefics3_utils.Idefics3MLLM",
    "use_tokenizer": false,
    "supports_multiple_images": true,
    "trust_remote_code": true,
    "use_bf16": false,
    "output_split_prefix": "Assistant:",
    "low_cpu_mem_usage": true,
    "release_date": "05-08-24",
    "open_weight": true,
    "parameters": "8B"
  },
  {
    "model_name": "dolphin-vision-72b",
    "backend": "huggingface_multimodal",
    "huggingface_id": "cognitivecomputations/dolphin-vision-72b",
    "automodel_type": "transformers.AutoModelForCausalLM",
    "model_class": "backends.multimodal_utils.dolphin_utils.DolphinMLLM",
    "use_tokenizer": true,
    "supports_multiple_images": true,
    "trust_remote_code": true,
    "use_bf16": true,
    "output_split_prefix": "",
    "low_cpu_mem_usage": true,
    "release_date": "28-06-24",
    "open_weight": true,
    "parameters": "72B"
  },
  {
    "model_name": "Phi-3.5-vision-instruct",
    "backend": "huggingface_multimodal",
    "huggingface_id": "microsoft/Phi-3.5-vision-instruct",
    "automodel_type": "transformers.AutoModelForCausalLM",
    "model_class": "backends.multimodal_utils.phi_utils.PhiMLLM",
    "supports_multiple_images": true,
    "trust_remote_code": true,
    "output_split_prefix": "",
    "low_cpu_mem_usage": true,
    "release_date": "17-08-24",
    "open_weight": true,
    "parameters": "4B"
  },
  {
    "model_name": "Pixtral-12B-2409",
    "backend": "huggingface_multimodal",
    "huggingface_id": "mistralai/Pixtral-12B-2409",
    "automodel_type": "vllm.LLM",
    "model_class": "backends.multimodal_utils.pixtral_utils.PixtralMLLM",
    "supports_multiple_images": true,
    "trust_remote_code": false,
    "output_split_prefix": "",
    "low_cpu_mem_usage": true,
    "release_date": "11-09-24",
    "open_weight": true,
    "parameters": "12B",
    "use_vllm": true,
    "tokenizer_mode": "mistral",
    "vllm_context": 8192
  }
]