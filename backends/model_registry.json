[
 
  {
      "model_name": "llava-v1.6-vicuna-13b-hf",
      "backend": "huggingface_multimodal",
      "huggingface_id": "llava-hf/llava-v1.6-vicuna-13b-hf",
      "model_type": "Vision2Seq",
      "output_split_prefix": "ASSISTANT:",
      "padding": true,
      "custom_chat_template": "A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions.{% for message in messages %}{% if message['role'] == 'user' %}{% if message['image'] %}USER:<image>\n{{message['content']}}{% else %}USER:\n{{message['content']}}{% endif %}{% elif message['role'] == 'assistant' %}ASSISTANT:{{message['content']}}{% endif %}{% endfor %}ASSISTANT:",
      "release_date": "2024-03-17",
      "open_weight": true,
      "parameters": "13B"
  },
  {
      "model_name": "llava-v1.6-vicuna-7b-hf",
      "backend": "huggingface_multimodal",
      "huggingface_id": "llava-hf/llava-v1.6-vicuna-7b-hf",
      "model_type": "Vision2Seq",
      "output_split_prefix": "ASSISTANT:",
      "padding": true,
      "custom_chat_template": "A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions.{% for message in messages %}{% if message['role'] == 'user' %}{% if message['image'] %}USER:<image>\n{{message['content']}}{% else %}USER:\n{{message['content']}}{% endif %}{% elif message['role'] == 'assistant' %}ASSISTANT:{{message['content']}}{% endif %}{% endfor %}ASSISTANT:",
      "release_date": "2024-03-17",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "idefics-80b-instruct",
      "backend": "huggingface_multimodal",
      "huggingface_id": "HuggingFaceM4/idefics-80b-instruct",
      "model_type": "Idefics",
      "eos_to_cull": "<end_of_utterance>",
      "output_split_prefix": "Assistant:",
      "supports_multiple_images": true,
      "release_date": "2023-07-24",
      "open_weight": true,
      "parameters": "80B"
  },
  {
      "model_name": "idefics-9b-instruct",
      "backend": "huggingface_multimodal",
      "huggingface_id": "HuggingFaceM4/idefics-9b-instruct",
      "model_type": "Idefics",
      "eos_to_cull": "<end_of_utterance>",
      "output_split_prefix": "Assistant:",
      "supports_multiple_images": true,
      "release_date": "2023-07-24",
      "open_weight": true,
      "parameters": "9B"
  },
  {
    "model_name": "InternVL2-Llama3-76B",
    "backend": "huggingface_multimodal",
    "huggingface_id": "OpenGVLab/InternVL2-Llama3-76B",
    "automodel_type": "transformers.AutoModel",
    "model_class": "backends.multimodal_utils.internvl_utils.InternvlMLLM",
    "use_tokenizer": true,
    "supports_multiple_images": true,
    "trust_remote_code": true,
    "use_bf16": true,
    "use_fast": false,
    "output_split_prefix": "Assistant:",
    "load_in_8bit": false,
    "low_cpu_mem_usage": true,
    "custom_device_map": true,
    "device_map": "backends.multimodal_utils.internvl_utils.split_model",
    "release_date": "2024-07-15",
    "open_weight": true,
    "parameters": "76B"
  },
  {
    "model_name": "InternVL2-40B",
    "backend": "huggingface_multimodal",
    "huggingface_id": "OpenGVLab/InternVL2-40B",
    "automodel_type": "transformers.AutoModel",
    "model_class": "backends.multimodal_utils.internvl_utils.InternvlMLLM",
    "use_tokenizer": true,
    "supports_multiple_images": true,
    "trust_remote_code": true,
    "use_bf16": true,
    "use_fast": false,
    "output_split_prefix": "Assistant:",
    "load_in_8bit": false,
    "low_cpu_mem_usage": true,
    "custom_device_map": true,
    "device_map": "backends.multimodal_utils.internvl_utils.split_model",
    "release_date": "2024-07-15",
    "open_weight": true,
    "parameters": "40B"
  },
  {
    "model_name": "InternVL2-26B",
    "backend": "huggingface_multimodal",
    "huggingface_id": "OpenGVLab/InternVL2-26B",
    "automodel_type": "transformers.AutoModel",
    "model_class": "backends.multimodal_utils.internvl_utils.InternvlMLLM",
    "use_tokenizer": true,
    "supports_multiple_images": true,
    "trust_remote_code": true,
    "use_bf16": true,
    "use_fast": false,
    "output_split_prefix": "Assistant:",
    "load_in_8bit": false,
    "low_cpu_mem_usage": true,
    "custom_device_map": true,
    "device_map": "backends.multimodal_utils.internvl_utils.split_model",
    "release_date": "2024-07-15",
    "open_weight": true,
    "parameters": "26B"
  },
  {
    "model_name": "InternVL2-8B",
    "backend": "huggingface_multimodal",
    "huggingface_id": "OpenGVLab/InternVL2-8B",
    "model_class": "transformers.AutoModel",
    "model_config": {
        "torch_dtype": "auto",
        "load_in_8bit": true,
        "low_cpu_mem_usage": true,
        "use_flash_attn": true,
        "device_map": "backends.multimodal_utils.split_model"
    },
    "processor_class": "transformers.AutoTokenizer",
    "processor_config": {
        "use_fast": false
    },
    "trust_remote_code": true,
    "do_sample": true,
    "supports_multiple_images": true,
    "release_date": "2024-07-15",
    "open_weight": true,
    "parameters": "8B"
  },
  {
    "model_name": "internlm-xcomposer2d5-7b",
    "backend": "huggingface_multimodal",
    "huggingface_id": "internlm/internlm-xcomposer2d5-7b",
    "automodel_type": "transformers.AutoModel",
    "model_class": "backends.multimodal_utils.intern_utils.InternlmMLLM",
    "use_tokenizer": true,
    "supports_multiple_images": true,
    "trust_remote_code": true,
    "use_bf16": true,
    "output_split_prefix": "",
    "not_distributed": true,
    "release_date": "2024-07-02",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "Idefics3-8B-Llama3",
    "backend": "huggingface_multimodal",
    "huggingface_id": "HuggingFaceM4/Idefics3-8B-Llama3",
    "automodel_type": "transformers.AutoModelForVision2Seq",
    "model_class": "backends.multimodal_utils.idefics3_utils.Idefics3MLLM",
    "use_tokenizer": false,
    "supports_multiple_images": true,
    "trust_remote_code": true,
    "use_bf16": false,
    "output_split_prefix": "Assistant:",
    "low_cpu_mem_usage": true,
    "release_date": "2024-08-05",
    "open_weight": true,
    "parameters": "8B"
  },
  {
    "model_name": "dolphin-vision-72b",
    "backend": "huggingface_multimodal",
    "huggingface_id": "cognitivecomputations/dolphin-vision-72b",
    "automodel_type": "transformers.AutoModelForCausalLM",
    "model_class": "backends.multimodal_utils.dolphin_utils.DolphinMLLM",
    "use_tokenizer": true,
    "supports_multiple_images": true,
    "trust_remote_code": true,
    "use_bf16": true,
    "output_split_prefix": "",
    "low_cpu_mem_usage": true,
    "release_date": "2024-06-28",
    "open_weight": true,
    "parameters": "72B"
  },
  {
    "model_name": "Phi-3.5-vision-instruct",
    "backend": "huggingface_multimodal",
    "huggingface_id": "microsoft/Phi-3.5-vision-instruct",
    "automodel_type": "transformers.AutoModelForCausalLM",
    "model_class": "backends.multimodal_utils.phi_utils.PhiMLLM",
    "supports_multiple_images": true,
    "trust_remote_code": true,
    "output_split_prefix": "",
    "low_cpu_mem_usage": true,
    "release_date": "2024-08-17",
    "open_weight": true,
    "parameters": "4B"
  },
  {
    "model_name": "Pixtral-12B-2409",
    "backend": "huggingface_multimodal",
    "huggingface_id": "mistralai/Pixtral-12B-2409",
    "automodel_type": "vllm.LLM",
    "model_class": "backends.multimodal_utils.pixtral_utils.PixtralMLLM",
    "supports_multiple_images": true,
    "trust_remote_code": false,
    "output_split_prefix": "",
    "low_cpu_mem_usage": true,
    "release_date": "2024-09-11",
    "open_weight": true,
    "parameters": "12B",
    "use_vllm": true,
    "tokenizer_mode": "mistral",
    "vllm_context": 8192
  },
  {
    "model_name": "Meta-Llama-3.1-70B-Instruct-FP8-neuralmagic-1gpu",
    "backend": "vllm",
    "huggingface_id": "neuralmagic/Meta-Llama-3.1-70B-Instruct-FP8",
    "number_gpus": 1,
    "premade_chat_template": true,
    "eos_to_cull": "<\\|eot_id\\|>",
    "release_date": "2023-07-23",
    "open_weight": true,
    "parameters": "70B"
  },
  {
    "model_name": "Meta-Llama-3.1-70B-Instruct-FP8-neuralmagic-1gpu-4k",
    "backend": "vllm",
    "huggingface_id": "neuralmagic/Meta-Llama-3.1-70B-Instruct-FP8",
    "number_gpus": 1,
    "context_limit": 4096,
    "premade_chat_template": true,
    "eos_to_cull": "<\\|eot_id\\|>",
    "release_date": "2023-07-23",
    "open_weight": true,
    "parameters": "70B"
  },
  {
    "model_name": "Meta-Llama-3.1-70B-Instruct-FP8-neuralmagic-1gpu-8k",
    "backend": "vllm",
    "huggingface_id": "neuralmagic/Meta-Llama-3.1-70B-Instruct-FP8",
    "number_gpus": 1,
    "context_limit": 8192,
    "premade_chat_template": true,
    "eos_to_cull": "<\\|eot_id\\|>",
    "release_date": "2023-07-23",
    "open_weight": true,
    "parameters": "70B"
  },
  {
    "model_name": "Meta-Llama-3.1-70B-Instruct-FP8-neuralmagic-2gpu",
    "backend": "vllm",
    "huggingface_id": "neuralmagic/Meta-Llama-3.1-70B-Instruct-FP8",
    "number_gpus": 2,
    "premade_chat_template": true,
    "eos_to_cull": "<\\|eot_id\\|>",
    "release_date": "2023-07-23",
    "open_weight": true,
    "parameters": "70B"
  }
]